version: '3.7'

services:
  hadoop:
    container_name: hadoop
    image: marcelmittelstaedt/spark_base:latest
    ports:
      - "8088:8088"  # Web UI f端r YARN
      - "9870:9870"  # HDFS Web UI
      - "9864:9864"  # HDFS Web UI
      - "10000:10000"  # HiveServer2
      - "8032:8032"  # Resource Manager
      - "8030:8030"
      - "8031:8031"
      - "9000:9000"  # HDFS Namenode
      - "8888:8888"  # Jupyter
    volumes:
      - ./airflow/notebooks:/home/hadoop/airflow/notebooks/
    networks:
      - bigdatanet

  airflow:
    container_name: airflow
    build: ./airflow
    image: azizcarducci/airflow:latest
    ports:
      - "8080:8080"  # Web UI f端r Airflow
    environment:
      - LOAD_EX=n
      - EXECUTOR=LocalExecutor
    volumes:
      - ./airflow/dags:/home/airflow/airflow/dags/
      - ./airflow/python:/home/airflow/airflow/python/
    networks:
      - bigdatanet

  mysql:
    container_name: mysql
    image: mysql:latest
    environment:
      MYSQL_ROOT_PASSWORD: rootpassword  # Root-Passwort f端r MySQL
      MYSQL_DATABASE: mtg_database         # Standarddatenbank
      MYSQL_USER: user                   # Benutzername
      MYSQL_PASSWORD: userpassword       # Benutzer-Passwort
    ports:
      - "3306:3306"  # Standard MySQL-Port
    networks:
      - bigdatanet


  backend:
    container_name: backend
    build: ./Backend
    image: my-backend:latest
    ports:
      - "5000:5000"  # Port f端r das Backend
    networks:
      - bigdatanet
    environment:
      - DB_HOST=mysql
      - DB_PORT=3306
      - DB_USER=root
      - DB_PASSWORD=userpassword
      - DB_NAME=mtg_database
    depends_on:
      - mysql	

  frontend:
    container_name: frontend
    build: ./Frontend
    command: ng serve --host 0.0.0.0
    ports:
      - "4200:4200"
    networks:
      bigdatanet:

volumes:
        mysql:

networks:
  bigdatanet:
    driver: bridge
